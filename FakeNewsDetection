{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8022663,"sourceType":"datasetVersion","datasetId":4727630},{"sourceId":10696160,"sourceType":"datasetVersion","datasetId":6628008},{"sourceId":177109926,"sourceType":"kernelVersion"}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ","metadata":{}},{"cell_type":"code","source":"!pip install transformers\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nimport nltk\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nimport torch\nfrom transformers import BertTokenizer, BertForSequenceClassification, pipeline\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T17:03:40.960411Z","iopub.execute_input":"2025-02-08T17:03:40.960636Z","iopub.status.idle":"2025-02-08T17:03:55.635479Z","shell.execute_reply.started":"2025-02-08T17:03:40.960614Z","shell.execute_reply":"2025-02-08T17:03:55.634793Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_fake = pd.read_csv('/kaggle/input/fake-news-data/Fake.csv')\ndf_fake.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T17:03:55.636770Z","iopub.execute_input":"2025-02-08T17:03:55.637302Z","iopub.status.idle":"2025-02-08T17:03:56.811638Z","shell.execute_reply.started":"2025-02-08T17:03:55.637278Z","shell.execute_reply":"2025-02-08T17:03:56.810638Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_true = pd.read_csv('/kaggle/input/fake-news-data/True.csv')\ndf_true.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T17:03:56.812694Z","iopub.execute_input":"2025-02-08T17:03:56.812994Z","iopub.status.idle":"2025-02-08T17:03:57.851903Z","shell.execute_reply.started":"2025-02-08T17:03:56.812973Z","shell.execute_reply":"2025-02-08T17:03:57.851050Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_fake['label'] = 'fake'\ndf_true['label'] = 'true'\n\n# Combine the two datasets\ndf = pd.concat([df_fake, df_true], ignore_index=True)\ndf.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T17:03:57.852740Z","iopub.execute_input":"2025-02-08T17:03:57.853024Z","iopub.status.idle":"2025-02-08T17:03:57.869218Z","shell.execute_reply.started":"2025-02-08T17:03:57.853001Z","shell.execute_reply":"2025-02-08T17:03:57.868413Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = df.sample(frac=1, random_state=42).reset_index(drop=True)\ndf.head()\n#data shuffle","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T17:03:57.870182Z","iopub.execute_input":"2025-02-08T17:03:57.870526Z","iopub.status.idle":"2025-02-08T17:03:57.904120Z","shell.execute_reply.started":"2025-02-08T17:03:57.870503Z","shell.execute_reply":"2025-02-08T17:03:57.903510Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check for null values\nprint(df.isnull().sum())\n\n# Remove any rows with null values (if necessary)\ndf = df.dropna()\n\n# Inspect columns\nprint(df.columns)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T17:03:57.904850Z","iopub.execute_input":"2025-02-08T17:03:57.905137Z","iopub.status.idle":"2025-02-08T17:03:57.935479Z","shell.execute_reply.started":"2025-02-08T17:03:57.905116Z","shell.execute_reply":"2025-02-08T17:03:57.934565Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\n\n# Define preprocessing function\nstop_words = set(stopwords.words('english'))\n\ndef preprocess_text(text):\n    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n    text = text.lower()  # Convert to lowercase\n    tokens = word_tokenize(text)  # Tokenize\n    tokens = [word for word in tokens if word not in stop_words]  # Remove stopwords\n    return \" \".join(tokens)\n\n# Apply preprocessing\ndf['text'] = df['text'].apply(preprocess_text)\ndf.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T17:03:57.937834Z","iopub.execute_input":"2025-02-08T17:03:57.938045Z","iopub.status.idle":"2025-02-08T17:05:02.026519Z","shell.execute_reply.started":"2025-02-08T17:03:57.938027Z","shell.execute_reply":"2025-02-08T17:05:02.025665Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = df['text']  # Features (text)\ny = df['label']  # Target (fake or true)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T17:05:02.027801Z","iopub.execute_input":"2025-02-08T17:05:02.028033Z","iopub.status.idle":"2025-02-08T17:05:02.039197Z","shell.execute_reply.started":"2025-02-08T17:05:02.028014Z","shell.execute_reply":"2025-02-08T17:05:02.038518Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\nvectorizer = TfidfVectorizer(max_features=5000)\nX_train_tfidf = vectorizer.fit_transform(X_train)\nX_test_tfidf = vectorizer.transform(X_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T17:05:02.040229Z","iopub.execute_input":"2025-02-08T17:05:02.040564Z","iopub.status.idle":"2025-02-08T17:05:10.096545Z","shell.execute_reply.started":"2025-02-08T17:05:02.040531Z","shell.execute_reply":"2025-02-08T17:05:10.095398Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\n# Train the model\nmodel = LogisticRegression()\nmodel.fit(X_train_tfidf, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_tfidf)\n\n# Evaluate the model\nprint(f'Accuracy: {accuracy_score(y_test, y_pred)}')\nprint(f'Precision: {precision_score(y_test, y_pred, pos_label=\"fake\")}')\nprint(f'Recall: {recall_score(y_test, y_pred, pos_label=\"fake\")}')\nprint(f'F1 Score: {f1_score(y_test, y_pred, pos_label=\"fake\")}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T17:05:10.097525Z","iopub.execute_input":"2025-02-08T17:05:10.097853Z","iopub.status.idle":"2025-02-08T17:05:11.162453Z","shell.execute_reply.started":"2025-02-08T17:05:10.097814Z","shell.execute_reply":"2025-02-08T17:05:11.161729Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.to_csv('processed_fake_news.csv', index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T17:05:11.163233Z","iopub.execute_input":"2025-02-08T17:05:11.163470Z","iopub.status.idle":"2025-02-08T17:05:12.768228Z","shell.execute_reply.started":"2025-02-08T17:05:11.163451Z","shell.execute_reply":"2025-02-08T17:05:12.767577Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.svm import SVC\n\n# Train the SVM model\nsvm_model = SVC(kernel='linear')\nsvm_model.fit(X_train_tfidf, y_train)\n\n# Make predictions\ny_pred_svm = svm_model.predict(X_test_tfidf)\n\n# Evaluate the SVM model\nprint(f'SVM Accuracy: {accuracy_score(y_test, y_pred_svm)}')\nprint(f'SVM Precision: {precision_score(y_test, y_pred_svm, pos_label=\"fake\")}')\nprint(f'SVM Recall: {recall_score(y_test, y_pred_svm, pos_label=\"fake\")}')\nprint(f'SVM F1 Score: {f1_score(y_test, y_pred_svm, pos_label=\"fake\")}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T17:15:43.342054Z","iopub.execute_input":"2025-02-08T17:15:43.342351Z","iopub.status.idle":"2025-02-08T17:20:40.180849Z","shell.execute_reply.started":"2025-02-08T17:15:43.342307Z","shell.execute_reply":"2025-02-08T17:20:40.179967Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\n# Train the Random Forest model\nrf_model = RandomForestClassifier(n_estimators=100, random_state=42)\nrf_model.fit(X_train_tfidf, y_train)\n\n# Make predictions\ny_pred_rf = rf_model.predict(X_test_tfidf)\n\n# Evaluate the Random Forest model\nprint(f'Random Forest Accuracy: {accuracy_score(y_test, y_pred_rf)}')\nprint(f'Random Forest Precision: {precision_score(y_test, y_pred_rf, pos_label=\"fake\")}')\nprint(f'Random Forest Recall: {recall_score(y_test, y_pred_rf, pos_label=\"fake\")}')\nprint(f'Random Forest F1 Score: {f1_score(y_test, y_pred_rf, pos_label=\"fake\")}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T17:20:40.181847Z","iopub.execute_input":"2025-02-08T17:20:40.182171Z","iopub.status.idle":"2025-02-08T17:21:33.633288Z","shell.execute_reply.started":"2025-02-08T17:20:40.182138Z","shell.execute_reply":"2025-02-08T17:21:33.632344Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"chunk_size = 1000 # Reduce to 1000 or smaller\ntrain_data_chunks = [X_train[i:i+chunk_size] for i in range(0, len(X_train), chunk_size)]\ntrain_labels_chunks = [y_train[i:i+chunk_size] for i in range(0, len(y_train), chunk_size)]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T17:37:44.871662Z","iopub.execute_input":"2025-02-08T17:37:44.871975Z","iopub.status.idle":"2025-02-08T17:37:44.878009Z","shell.execute_reply.started":"2025-02-08T17:37:44.871951Z","shell.execute_reply":"2025-02-08T17:37:44.877126Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T17:37:52.631574Z","iopub.execute_input":"2025-02-08T17:37:52.631961Z","iopub.status.idle":"2025-02-08T17:37:52.636098Z","shell.execute_reply.started":"2025-02-08T17:37:52.631929Z","shell.execute_reply":"2025-02-08T17:37:52.635082Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"accumulation_steps = 4  # Number of steps to accumulate gradients\nfor i, (chunk, labels) in enumerate(zip(train_data_chunks, train_labels_chunks)):\n    train_inputs, train_labels = tokenize_data(chunk, labels)\n    bert_model.train()\n    \n    for j in range(0, len(train_inputs['input_ids']), accumulation_steps):\n        # Mini-batch processing\n        batch_inputs = {key: val[j:j+accumulation_steps] for key, val in train_inputs.items()}\n        batch_labels = train_labels[j:j+accumulation_steps]\n        \n        optimizer.zero_grad()\n        outputs = bert_model(**batch_inputs, labels=batch_labels)\n        loss = outputs.loss / accumulation_steps\n        loss.backward()\n    \n    optimizer.step()\n    print(f'Chunk {i+1}, Loss: {loss.item()}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T17:38:01.165908Z","iopub.execute_input":"2025-02-08T17:38:01.166238Z","iopub.status.idle":"2025-02-08T18:38:11.372736Z","shell.execute_reply.started":"2025-02-08T17:38:01.166211Z","shell.execute_reply":"2025-02-08T18:38:11.371832Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import DataLoader, TensorDataset\nimport numpy as np\n\n# Tokenize the entire test set\ntest_inputs, test_labels = tokenize_data(X_test, y_test)\n\n# Convert to DataLoader for mini-batch processing\ntest_dataset = TensorDataset(test_inputs['input_ids'], test_inputs['attention_mask'], test_labels)\ntest_loader = DataLoader(test_dataset, batch_size=64)  # Adjust batch size based on memory availability\n\n# Evaluate the model\nbert_model.eval()\nall_predictions = []\nall_labels = []\n\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids, attention_mask, labels = [x.to(device) for x in batch]\n        outputs = bert_model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n        logits = outputs.logits\n        predictions = torch.argmax(logits, dim=1)\n\n        # Store predictions and labels\n        all_predictions.extend(predictions.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n\n# Calculate metrics\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\nprint(\"Accuracy:\", accuracy_score(all_labels, all_predictions))\nprint(\"Precision:\", precision_score(all_labels, all_predictions))\nprint(\"Recall:\", recall_score(all_labels, all_predictions))\nprint(\"F1 Score:\", f1_score(all_labels, all_predictions))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T18:38:45.858281Z","iopub.execute_input":"2025-02-08T18:38:45.858592Z","iopub.status.idle":"2025-02-08T18:44:22.987854Z","shell.execute_reply.started":"2025-02-08T18:38:45.858567Z","shell.execute_reply":"2025-02-08T18:44:22.986898Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the model and tokenizer\nmodel_save_path = \"./bert_fake_news_model\"\nbert_model.save_pretrained(model_save_path)\ntokenizer.save_pretrained(model_save_path)\n\nprint(f\"Model and tokenizer saved to {model_save_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T18:45:35.277283Z","iopub.execute_input":"2025-02-08T18:45:35.277617Z","iopub.status.idle":"2025-02-08T18:45:36.253650Z","shell.execute_reply.started":"2025-02-08T18:45:35.277593Z","shell.execute_reply":"2025-02-08T18:45:36.252876Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Example text data for inference\nexample_texts = [\"This is fake news!\", \"This is true news.\"]\n\n# Tokenize the example texts\ninference_inputs = tokenizer(example_texts, padding=True, truncation=True, max_length=128, return_tensors=\"pt\").to(device)\n\n# Make predictions\nwith torch.no_grad():\n    outputs = bert_model(**inference_inputs)\n    predictions = torch.argmax(outputs.logits, dim=1)\n\n# Map predictions to labels\nlabels = [\"true\", \"fake\"]\npredicted_labels = [labels[pred] for pred in predictions.cpu().numpy()]\nprint(\"Predictions:\", predicted_labels)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T18:45:40.499434Z","iopub.execute_input":"2025-02-08T18:45:40.499860Z","iopub.status.idle":"2025-02-08T18:45:40.556398Z","shell.execute_reply.started":"2025-02-08T18:45:40.499820Z","shell.execute_reply":"2025-02-08T18:45:40.555501Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\ncm = confusion_matrix(all_labels, all_predictions)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"True\", \"Fake\"])\ndisp.plot(cmap=\"Blues\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T18:45:48.490401Z","iopub.execute_input":"2025-02-08T18:45:48.490710Z","iopub.status.idle":"2025-02-08T18:45:48.791348Z","shell.execute_reply.started":"2025-02-08T18:45:48.490686Z","shell.execute_reply":"2025-02-08T18:45:48.790544Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define a small dummy input\ndummy_input_ids = torch.randint(0, tokenizer.vocab_size, (1, 128)).to(\"cpu\")  # Batch size 1, sequence length 128\ndummy_attention_mask = torch.ones((1, 128)).to(\"cpu\")\n\n# Create a wrapper model for TorchScript\nclass WrapperModel(torch.nn.Module):\n    def __init__(self, model):\n        super(WrapperModel, self).__init__()\n        self.model = model\n\n    def forward(self, input_ids, attention_mask):\n        # Extract only the logits from the output dictionary\n        output = self.model(input_ids=input_ids, attention_mask=attention_mask)\n        return output.logits  # Return logits as a tensor\n\n# Wrap the model\nwrapped_model = WrapperModel(bert_model)\n\n# Trace the wrapped model\ntraced_model = torch.jit.trace(wrapped_model, (dummy_input_ids, dummy_attention_mask))\ntraced_model.save(\"bert_fake_news_model.pt\")\nprint(\"Model saved as TorchScript.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T18:50:56.542959Z","iopub.execute_input":"2025-02-08T18:50:56.543281Z","iopub.status.idle":"2025-02-08T18:50:59.048360Z","shell.execute_reply.started":"2025-02-08T18:50:56.543253Z","shell.execute_reply":"2025-02-08T18:50:59.047423Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import T5Tokenizer, T5ForConditionalGeneration\n\n# Load T5 model\nt5_tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\nt5_model = T5ForConditionalGeneration.from_pretrained(\"t5-small\").to(device)\n\n# Summarize a text\ntext_to_summarize = \"This is a long news article to be summarized for better understanding.\"\ninputs = t5_tokenizer(\"summarize: \" + text_to_summarize, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\nsummary_ids = t5_model.generate(inputs.input_ids, max_length=50, min_length=10, length_penalty=2.0, num_beams=4, early_stopping=True)\n\n# Decode the summary\nsummary = t5_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\nprint(\"Summary:\", summary)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T18:51:24.500115Z","iopub.execute_input":"2025-02-08T18:51:24.500439Z","iopub.status.idle":"2025-02-08T18:51:29.365207Z","shell.execute_reply.started":"2025-02-08T18:51:24.500414Z","shell.execute_reply":"2025-02-08T18:51:29.364340Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load a news article from your dataset\nnews_article = \"Your real news article text goes here.\"\n\n# Tokenize and summarize\ninputs = t5_tokenizer(\"summarize: \" + news_article, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\nsummary_ids = t5_model.generate(inputs.input_ids, max_length=50, min_length=10, length_penalty=2.0, num_beams=4, early_stopping=True)\n\n# Decode the summary\nsummary = t5_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\nprint(\"Original Article:\", news_article)\nprint(\"Summary:\", summary)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T18:51:31.860307Z","iopub.execute_input":"2025-02-08T18:51:31.860608Z","iopub.status.idle":"2025-02-08T18:51:32.020004Z","shell.execute_reply.started":"2025-02-08T18:51:31.860585Z","shell.execute_reply":"2025-02-08T18:51:32.019123Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install rouge-score\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T18:51:39.899832Z","iopub.execute_input":"2025-02-08T18:51:39.900151Z","iopub.status.idle":"2025-02-08T18:51:45.213790Z","shell.execute_reply.started":"2025-02-08T18:51:39.900124Z","shell.execute_reply":"2025-02-08T18:51:45.212808Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from rouge_score import rouge_scorer\n\n# Define the ground truth and generated summary\nreference = \"This is the ground truth summary of the news article.\"\ncandidate = \"This is a summary of the news article.\"\n\n# Compute ROUGE scores\nscorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\nscores = scorer.score(reference, candidate)\nprint(\"ROUGE Scores:\", scores)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T18:51:45.859647Z","iopub.execute_input":"2025-02-08T18:51:45.859956Z","iopub.status.idle":"2025-02-08T18:51:45.875736Z","shell.execute_reply.started":"2025-02-08T18:51:45.859927Z","shell.execute_reply":"2025-02-08T18:51:45.875092Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from rouge_score import rouge_scorer\n\n# Example references and candidates\nreferences = [\n    \"This is the ground truth summary of the first news article.\",\n    \"This is the ground truth summary of the second news article.\"\n]\ncandidates = [\n    \"This is the summary of the first article.\",\n    \"This is the summary of the second article.\"\n]\n\n# Initialize ROUGE scorer\nscorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n\n# Evaluate ROUGE scores\nfor i, (ref, cand) in enumerate(zip(references, candidates)):\n    scores = scorer.score(ref, cand)\n    print(f\"Article {i+1} ROUGE Scores:\")\n    print(f\"ROUGE-1: {scores['rouge1']}\")\n    print(f\"ROUGE-2: {scores['rouge2']}\")\n    print(f\"ROUGE-L: {scores['rougeL']}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T18:51:55.339783Z","iopub.execute_input":"2025-02-08T18:51:55.340083Z","iopub.status.idle":"2025-02-08T18:51:55.347977Z","shell.execute_reply.started":"2025-02-08T18:51:55.340060Z","shell.execute_reply":"2025-02-08T18:51:55.347360Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Example dataset\ndata = {\n    \"ground_truth_summary\": [\n        \"This is the ground truth summary for article 1.\",\n        \"This is the ground truth summary for article 2.\"\n    ],\n    \"generated_summary\": [\n        \"This is the generated summary for article 1.\",\n        \"This is the generated summary for article 2.\"\n    ]\n}\n\n# Create a DataFrame\ndataset = pd.DataFrame(data)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T18:52:04.143745Z","iopub.execute_input":"2025-02-08T18:52:04.144065Z","iopub.status.idle":"2025-02-08T18:52:04.149279Z","shell.execute_reply.started":"2025-02-08T18:52:04.144034Z","shell.execute_reply":"2025-02-08T18:52:04.148372Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from statistics import mean\nfrom rouge_score import rouge_scorer\n\n# Initialize ROUGE scorer\nscorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n\n# Initialize lists to store scores\nrouge1_scores, rouge2_scores, rougeL_scores = [], [], []\n\n# Loop through the dataset\nfor i, row in dataset.iterrows():\n    ref = row['ground_truth_summary']\n    cand = row['generated_summary']\n    scores = scorer.score(ref, cand)\n    \n    # Collect scores\n    rouge1_scores.append(scores['rouge1'].fmeasure)\n    rouge2_scores.append(scores['rouge2'].fmeasure)\n    rougeL_scores.append(scores['rougeL'].fmeasure)\n\n# Calculate average scores\nprint(f\"Average ROUGE-1: {mean(rouge1_scores):.4f}\")\nprint(f\"Average ROUGE-2: {mean(rouge2_scores):.4f}\")\nprint(f\"Average ROUGE-L: {mean(rougeL_scores):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T18:52:10.428492Z","iopub.execute_input":"2025-02-08T18:52:10.428779Z","iopub.status.idle":"2025-02-08T18:52:10.441359Z","shell.execute_reply.started":"2025-02-08T18:52:10.428756Z","shell.execute_reply":"2025-02-08T18:52:10.440545Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset = pd.read_csv(\"processed_fake_news.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T18:52:16.596375Z","iopub.execute_input":"2025-02-08T18:52:16.596691Z","iopub.status.idle":"2025-02-08T18:52:17.595368Z","shell.execute_reply.started":"2025-02-08T18:52:16.596666Z","shell.execute_reply":"2025-02-08T18:52:17.594678Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset['ground_truth_summary'] = dataset['title']\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T18:52:24.041355Z","iopub.execute_input":"2025-02-08T18:52:24.041642Z","iopub.status.idle":"2025-02-08T18:52:24.047262Z","shell.execute_reply.started":"2025-02-08T18:52:24.041621Z","shell.execute_reply":"2025-02-08T18:52:24.046589Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset['text'] = dataset['text'].fillna(\"\")\ndataset['text'] = dataset['text'].astype(str)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T18:53:11.920299Z","iopub.execute_input":"2025-02-08T18:53:11.920668Z","iopub.status.idle":"2025-02-08T18:53:11.938485Z","shell.execute_reply.started":"2025-02-08T18:53:11.920638Z","shell.execute_reply":"2025-02-08T18:53:11.937576Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset = dataset.sample(1000)  # Process a random subset of 1000 rows\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T18:54:14.766714Z","iopub.execute_input":"2025-02-08T18:54:14.767037Z","iopub.status.idle":"2025-02-08T18:54:14.780062Z","shell.execute_reply.started":"2025-02-08T18:54:14.767008Z","shell.execute_reply":"2025-02-08T18:54:14.779329Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"generated_summaries = []\n\nbatch_size = 10  # Adjust based on your system's capacity\nfor i in range(0, len(dataset), batch_size):\n    batch_texts = dataset['text'][i:i+batch_size].tolist()\n    \n\n    inputs = t5_tokenizer(\n    [\"summarize: \" + text[:512] for text in batch_texts],  # Limit to 512 characters\n    return_tensors=\"pt\",\n    padding=True,\n    truncation=True\n).to(device)\n\n    summary_ids = t5_model.generate(inputs.input_ids, max_length=50, min_length=10, num_beams=4, early_stopping=True)\n    batch_summaries = [t5_tokenizer.decode(ids, skip_special_tokens=True) for ids in summary_ids]\n    generated_summaries.extend(batch_summaries)\n\ndataset['generated_summary'] = generated_summaries\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T18:54:19.407663Z","iopub.execute_input":"2025-02-08T18:54:19.407949Z","iopub.status.idle":"2025-02-08T18:56:00.450456Z","shell.execute_reply.started":"2025-02-08T18:54:19.407927Z","shell.execute_reply":"2025-02-08T18:56:00.449078Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset.to_csv(\"processed_fake_news_with_summaries.csv\", index=False)\nprint(\"Dataset with generated summaries saved.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T18:56:00.452022Z","iopub.execute_input":"2025-02-08T18:56:00.452373Z","iopub.status.idle":"2025-02-08T18:56:00.508271Z","shell.execute_reply.started":"2025-02-08T18:56:00.452337Z","shell.execute_reply":"2025-02-08T18:56:00.507253Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from rouge_score import rouge_scorer\nfrom statistics import mean\n\n# Initialize ROUGE scorer\nscorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n\n# Initialize lists to store scores\nrouge1_scores, rouge2_scores, rougeL_scores = [], [], []\n\n# Loop through the dataset\nfor i, row in dataset.iterrows():\n    ref = row['ground_truth_summary']  # True summary\n    cand = row['generated_summary']    # Model-generated summary\n    scores = scorer.score(ref, cand)\n    \n    # Collect scores\n    rouge1_scores.append(scores['rouge1'].fmeasure)\n    rouge2_scores.append(scores['rouge2'].fmeasure)\n    rougeL_scores.append(scores['rougeL'].fmeasure)\n\n# Assign scores to the dataset\ndataset['rouge1_score'] = rouge1_scores\ndataset['rouge2_score'] = rouge2_scores\ndataset['rougeL_score'] = rougeL_scores\n\n# Calculate and display average scores\nprint(f\"Average ROUGE-1: {mean(rouge1_scores):.4f}\")\nprint(f\"Average ROUGE-2: {mean(rouge2_scores):.4f}\")\nprint(f\"Average ROUGE-L: {mean(rougeL_scores):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T18:56:00.510054Z","iopub.execute_input":"2025-02-08T18:56:00.510351Z","iopub.status.idle":"2025-02-08T18:56:01.747297Z","shell.execute_reply.started":"2025-02-08T18:56:00.510296Z","shell.execute_reply":"2025-02-08T18:56:01.746368Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset.to_csv(\"processed_fake_news_with_rouge_scores.csv\", index=False)\nprint(\"Dataset with ROUGE scores saved.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T18:56:01.748632Z","iopub.execute_input":"2025-02-08T18:56:01.748989Z","iopub.status.idle":"2025-02-08T18:56:01.809175Z","shell.execute_reply.started":"2025-02-08T18:56:01.748954Z","shell.execute_reply":"2025-02-08T18:56:01.808117Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"worst_cases = dataset.nsmallest(5, 'rouge1_score')\nprint(worst_cases)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T18:56:01.810182Z","iopub.execute_input":"2025-02-08T18:56:01.810552Z","iopub.status.idle":"2025-02-08T18:56:01.829931Z","shell.execute_reply.started":"2025-02-08T18:56:01.810515Z","shell.execute_reply":"2025-02-08T18:56:01.828802Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Plot histogram of ROUGE-1 scores\nplt.hist(dataset['rouge1_score'], bins=20, alpha=0.7, label='ROUGE-1')\nplt.hist(dataset['rouge2_score'], bins=20, alpha=0.7, label='ROUGE-2')\nplt.hist(dataset['rougeL_score'], bins=20, alpha=0.7, label='ROUGE-L')\nplt.xlabel('ROUGE Scores')\nplt.ylabel('Frequency')\nplt.legend()\nplt.title('Distribution of ROUGE Scores')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T18:56:01.830907Z","iopub.execute_input":"2025-02-08T18:56:01.831271Z","iopub.status.idle":"2025-02-08T18:56:02.178434Z","shell.execute_reply.started":"2025-02-08T18:56:01.831245Z","shell.execute_reply":"2025-02-08T18:56:02.177310Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\n\n# Extract text and labels\ntexts = dataset['text']  # Replace 'text' with the column containing the news text\nlabels = dataset['label'].apply(lambda x: 1 if x == 'fake' else 0)  # Binary labels\n\n# Split into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n\n# Convert text to numerical features using TF-IDF\nvectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))  # Adjust max_features based on memory constraints\nX_train_tfidf = vectorizer.fit_transform(X_train)\nX_test_tfidf = vectorizer.transform(X_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T18:59:50.446884Z","iopub.execute_input":"2025-02-08T18:59:50.447200Z","iopub.status.idle":"2025-02-08T18:59:51.232777Z","shell.execute_reply.started":"2025-02-08T18:59:50.447176Z","shell.execute_reply":"2025-02-08T18:59:51.232095Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\n# Train Logistic Regression\nlr_model = LogisticRegression(max_iter=1000, random_state=42)\nlr_model.fit(X_train_tfidf, y_train)\n\n# Make predictions\ny_pred_lr = lr_model.predict(X_test_tfidf)\n\n# Evaluate the model\naccuracy_lr = accuracy_score(y_test, y_pred_lr)\nprecision_lr = precision_score(y_test, y_pred_lr)\nrecall_lr = recall_score(y_test, y_pred_lr)\nf1_lr = f1_score(y_test, y_pred_lr)\n\nprint(f\"Logistic Regression - Accuracy: {accuracy_lr:.4f}, Precision: {precision_lr:.4f}, Recall: {recall_lr:.4f}, F1 Score: {f1_lr:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T19:08:13.589294Z","iopub.execute_input":"2025-02-08T19:08:13.589602Z","iopub.status.idle":"2025-02-08T19:08:13.627271Z","shell.execute_reply.started":"2025-02-08T19:08:13.589580Z","shell.execute_reply":"2025-02-08T19:08:13.626402Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\n\n# Train Naive Bayes\nnb_model = MultinomialNB()\nnb_model.fit(X_train_tfidf, y_train)\n\n# Make predictions\ny_pred_nb = nb_model.predict(X_test_tfidf)\n\n# Evaluate the model\naccuracy_nb = accuracy_score(y_test, y_pred_nb)\nprecision_nb = precision_score(y_test, y_pred_nb)\nrecall_nb = recall_score(y_test, y_pred_nb)\nf1_nb = f1_score(y_test, y_pred_nb)\n\nprint(f\"Naive Bayes - Accuracy: {accuracy_nb:.4f}, Precision: {precision_nb:.4f}, Recall: {recall_nb:.4f}, F1 Score: {f1_nb:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T19:08:25.948172Z","iopub.execute_input":"2025-02-08T19:08:25.948517Z","iopub.status.idle":"2025-02-08T19:08:25.964129Z","shell.execute_reply.started":"2025-02-08T19:08:25.948486Z","shell.execute_reply":"2025-02-08T19:08:25.963387Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Create a DataFrame to summarize metrics\nmetrics = {\n    \"Model\": [\"Logistic Regression\", \"Naive Bayes\"],\n    \"Accuracy\": [accuracy_lr, accuracy_nb],\n    \"Precision\": [precision_lr, precision_nb],\n    \"Recall\": [recall_lr, recall_nb],\n    \"F1 Score\": [f1_lr, f1_nb]\n}\n\nmetrics_df = pd.DataFrame(metrics)\nprint(metrics_df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T19:08:33.770566Z","iopub.execute_input":"2025-02-08T19:08:33.770897Z","iopub.status.idle":"2025-02-08T19:08:33.779060Z","shell.execute_reply.started":"2025-02-08T19:08:33.770870Z","shell.execute_reply":"2025-02-08T19:08:33.778150Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Plot Accuracy Comparison\nplt.bar(metrics_df[\"Model\"], metrics_df[\"Accuracy\"], color=['blue', 'orange'])\nplt.title(\"Model Accuracy Comparison\")\nplt.xlabel(\"Model\")\nplt.ylabel(\"Accuracy\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T19:08:43.767619Z","iopub.execute_input":"2025-02-08T19:08:43.767937Z","iopub.status.idle":"2025-02-08T19:08:43.893405Z","shell.execute_reply.started":"2025-02-08T19:08:43.767910Z","shell.execute_reply":"2025-02-08T19:08:43.892658Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\n# Confusion matrix for Logistic Regression\ncm_lr = confusion_matrix(y_test, y_pred_lr)\nsns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues')\nplt.title(\"Logistic Regression Confusion Matrix\")\nplt.show()\n\n# Confusion matrix for Naive Bayes\ncm_nb = confusion_matrix(y_test, y_pred_nb)\nsns.heatmap(cm_nb, annot=True, fmt='d', cmap='Blues')\nplt.title(\"Naive Bayes Confusion Matrix\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T19:08:58.306892Z","iopub.execute_input":"2025-02-08T19:08:58.307404Z","iopub.status.idle":"2025-02-08T19:08:58.616173Z","shell.execute_reply.started":"2025-02-08T19:08:58.307363Z","shell.execute_reply":"2025-02-08T19:08:58.615151Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pickle\n\n# Save Logistic Regression model\nwith open(\"logistic_regression_model.pkl\", \"wb\") as file:\n    pickle.dump(lr_model, file)\n\n# Save Naive Bayes model\nwith open(\"naive_bayes_model.pkl\", \"wb\") as file:\n    pickle.dump(nb_model, file)\n\n# Save TF-IDF Vectorizer\nwith open(\"tfidf_vectorizer.pkl\", \"wb\") as file:\n    pickle.dump(vectorizer, file)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T19:09:16.742098Z","iopub.execute_input":"2025-02-08T19:09:16.742460Z","iopub.status.idle":"2025-02-08T19:09:16.800704Z","shell.execute_reply.started":"2025-02-08T19:09:16.742431Z","shell.execute_reply":"2025-02-08T19:09:16.799803Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Identify misclassified samples\nmisclassified_samples = X_test[y_test != y_pred_lr]\nprint(\"Misclassified samples by Logistic Regression:\")\nprint(misclassified_samples.head())\n\nmisclassified_samples_nb = X_test[y_test != y_pred_nb]\nprint(\"Misclassified samples by Naive Bayes:\")\nprint(misclassified_samples_nb.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T19:09:27.060290Z","iopub.execute_input":"2025-02-08T19:09:27.060656Z","iopub.status.idle":"2025-02-08T19:09:27.067990Z","shell.execute_reply.started":"2025-02-08T19:09:27.060625Z","shell.execute_reply":"2025-02-08T19:09:27.067193Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def tokenize_data(texts, labels):\n    texts = [str(text) for text in texts]  # Ensure all inputs are strings\n    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\").to(device)  # Move to GPU/CPU\n    labels = torch.tensor([1 if label == 'fake' else 0 for label in labels]).to(device)  # Move to GPU/CPU\n    return inputs, labels\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T19:13:20.723174Z","iopub.execute_input":"2025-02-08T19:13:20.723511Z","iopub.status.idle":"2025-02-08T19:13:20.728085Z","shell.execute_reply.started":"2025-02-08T19:13:20.723485Z","shell.execute_reply":"2025-02-08T19:13:20.727145Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nbert_model.to(device)  # Ensure model is on the same device\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T19:13:27.922667Z","iopub.execute_input":"2025-02-08T19:13:27.922952Z","iopub.status.idle":"2025-02-08T19:13:28.065193Z","shell.execute_reply.started":"2025-02-08T19:13:27.922929Z","shell.execute_reply":"2025-02-08T19:13:28.064475Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_inputs, test_labels = tokenize_data(X_test.tolist(), y_test.tolist())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T19:13:38.324924Z","iopub.execute_input":"2025-02-08T19:13:38.325220Z","iopub.status.idle":"2025-02-08T19:13:39.645762Z","shell.execute_reply.started":"2025-02-08T19:13:38.325197Z","shell.execute_reply":"2025-02-08T19:13:39.645033Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluate the model\nbert_model.eval()\n\nwith torch.no_grad():\n    outputs = bert_model(**test_inputs)  # Both `test_inputs` and the model are on `device`\n    logits = outputs.logits\n    bert_predictions = torch.argmax(logits, dim=1).cpu().numpy()  # Move predictions to CPU for evaluation\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T19:13:49.923100Z","iopub.execute_input":"2025-02-08T19:13:49.923405Z","iopub.status.idle":"2025-02-08T19:13:56.173266Z","shell.execute_reply.started":"2025-02-08T19:13:49.923380Z","shell.execute_reply":"2025-02-08T19:13:56.172280Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\n# Evaluate the predictions\naccuracy_bert = accuracy_score(y_test, bert_predictions)\nprecision_bert = precision_score(y_test, bert_predictions)\nrecall_bert = recall_score(y_test, bert_predictions)\nf1_bert = f1_score(y_test, bert_predictions)\n\n# Print metrics\nprint(f\"Accuracy: {accuracy_bert:.4f}\")\nprint(f\"Precision: {precision_bert:.4f}\")\nprint(f\"Recall: {recall_bert:.4f}\")\nprint(f\"F1 Score: {f1_bert:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T19:14:11.625238Z","iopub.execute_input":"2025-02-08T19:14:11.625667Z","iopub.status.idle":"2025-02-08T19:14:11.640372Z","shell.execute_reply.started":"2025-02-08T19:14:11.625631Z","shell.execute_reply":"2025-02-08T19:14:11.639692Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"metrics = {\n    \"Model\": [\"Logistic Regression\", \"Naive Bayes\", \"BERT\"],\n    \"Accuracy\": [accuracy_lr, accuracy_nb, accuracy_bert],\n    \"Precision\": [precision_lr, precision_nb, precision_bert],\n    \"Recall\": [recall_lr, recall_nb, recall_bert],\n    \"F1 Score\": [f1_lr, f1_nb, f1_bert]\n}\n\nmetrics_df = pd.DataFrame(metrics)\nprint(metrics_df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T19:14:17.841568Z","iopub.execute_input":"2025-02-08T19:14:17.841899Z","iopub.status.idle":"2025-02-08T19:14:17.849916Z","shell.execute_reply.started":"2025-02-08T19:14:17.841870Z","shell.execute_reply":"2025-02-08T19:14:17.849066Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\n# Define metrics for visualization\nmodels = metrics[\"Model\"]\naccuracy = metrics[\"Accuracy\"]\nprecision = metrics[\"Precision\"]\nrecall = metrics[\"Recall\"]\nf1_score = metrics[\"F1 Score\"]\n\nx = np.arange(len(models))  # Number of models\nwidth = 0.2  # Bar width\n\n# Create bar charts\nplt.figure(figsize=(10, 6))\nplt.bar(x - width * 1.5, accuracy, width, label=\"Accuracy\")\nplt.bar(x - width * 0.5, precision, width, label=\"Precision\")\nplt.bar(x + width * 0.5, recall, width, label=\"Recall\")\nplt.bar(x + width * 1.5, f1_score, width, label=\"F1 Score\")\n\n# Label the plot\nplt.xlabel(\"Models\")\nplt.ylabel(\"Scores\")\nplt.title(\"Model Comparison\")\nplt.xticks(x, models)\nplt.legend()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T19:14:58.323576Z","iopub.execute_input":"2025-02-08T19:14:58.323883Z","iopub.status.idle":"2025-02-08T19:14:58.505112Z","shell.execute_reply.started":"2025-02-08T19:14:58.323858Z","shell.execute_reply":"2025-02-08T19:14:58.504157Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Export metrics table\nmetrics_df.to_csv(\"model_comparison_metrics.csv\", index=False)\n\n# Save the plot\nplt.savefig(\"model_comparison_plot.png\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T19:15:11.422680Z","iopub.execute_input":"2025-02-08T19:15:11.423078Z","iopub.status.idle":"2025-02-08T19:15:11.447025Z","shell.execute_reply.started":"2025-02-08T19:15:11.423042Z","shell.execute_reply":"2025-02-08T19:15:11.446158Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"liar_dataset = pd.read_csv(\"/kaggle/input/liar-dataset/train.tsv\", sep=\"\\t\", header=None)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T19:23:35.577462Z","iopub.execute_input":"2025-02-08T19:23:35.577755Z","iopub.status.idle":"2025-02-08T19:23:35.666399Z","shell.execute_reply.started":"2025-02-08T19:23:35.577731Z","shell.execute_reply":"2025-02-08T19:23:35.665728Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(liar_dataset.shape)  # Displays the number of rows and columns\nprint(liar_dataset.columns)  # Displays the current column names\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T19:24:33.364595Z","iopub.execute_input":"2025-02-08T19:24:33.364934Z","iopub.status.idle":"2025-02-08T19:24:33.370197Z","shell.execute_reply.started":"2025-02-08T19:24:33.364908Z","shell.execute_reply":"2025-02-08T19:24:33.369537Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"liar_dataset = liar_dataset.iloc[:, :12]  # Keep only the first 12 columns\nliar_dataset.columns = [\n    'ID', 'label', 'statement', 'subject', 'speaker',\n    'speaker_job', 'state', 'party', 'barely_true',\n    'false', 'pants_on_fire', 'context'\n]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T19:24:55.153489Z","iopub.execute_input":"2025-02-08T19:24:55.153770Z","iopub.status.idle":"2025-02-08T19:24:55.159673Z","shell.execute_reply.started":"2025-02-08T19:24:55.153751Z","shell.execute_reply":"2025-02-08T19:24:55.158857Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"combined_dataset = pd.concat([dataset, liar_dataset], ignore_index=True)\nprint(combined_dataset.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T19:25:34.786953Z","iopub.execute_input":"2025-02-08T19:25:34.787270Z","iopub.status.idle":"2025-02-08T19:25:34.797577Z","shell.execute_reply.started":"2025-02-08T19:25:34.787246Z","shell.execute_reply":"2025-02-08T19:25:34.796678Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"combined_dataset.to_csv(\"expanded_dataset.csv\", index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T19:25:42.617021Z","iopub.execute_input":"2025-02-08T19:25:42.617314Z","iopub.status.idle":"2025-02-08T19:25:42.757452Z","shell.execute_reply.started":"2025-02-08T19:25:42.617293Z","shell.execute_reply":"2025-02-08T19:25:42.756765Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(combined_dataset['statement'].isnull().sum())\ncombined_dataset['statement'] = combined_dataset['statement'].fillna(\"Unknown\")\ncombined_dataset = combined_dataset.dropna(subset=['statement'])\nprint(combined_dataset['statement'].isnull().sum())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T19:26:55.648303Z","iopub.execute_input":"2025-02-08T19:26:55.648753Z","iopub.status.idle":"2025-02-08T19:26:55.669889Z","shell.execute_reply.started":"2025-02-08T19:26:55.648716Z","shell.execute_reply":"2025-02-08T19:26:55.668629Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T19:27:07.323133Z","iopub.execute_input":"2025-02-08T19:27:07.323450Z","iopub.status.idle":"2025-02-08T19:27:07.800507Z","shell.execute_reply.started":"2025-02-08T19:27:07.323427Z","shell.execute_reply":"2025-02-08T19:27:07.799827Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ntexts = combined_dataset['statement']  # Or your target text column\nlabels = combined_dataset['label'].apply(lambda x: 1 if x == 'fake' else 0)  # Adjust as needed\n\n# Convert text into numerical features\nvectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\nX = vectorizer.fit_transform(texts)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T19:27:24.414537Z","iopub.execute_input":"2025-02-08T19:27:24.414840Z","iopub.status.idle":"2025-02-08T19:27:24.865844Z","shell.execute_reply.started":"2025-02-08T19:27:24.414817Z","shell.execute_reply":"2025-02-08T19:27:24.864921Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n\n# Example: Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\nlr_model = LogisticRegression()\nlr_model.fit(X_train, y_train)\n\n# Evaluate the model\nfrom sklearn.metrics import classification_report\ny_pred = lr_model.predict(X_test)\nprint(classification_report(y_test, y_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T19:27:37.630373Z","iopub.execute_input":"2025-02-08T19:27:37.630662Z","iopub.status.idle":"2025-02-08T19:27:37.687926Z","shell.execute_reply.started":"2025-02-08T19:27:37.630640Z","shell.execute_reply":"2025-02-08T19:27:37.687110Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\n\nnb_model = MultinomialNB()\nnb_model.fit(X_train, y_train)\ny_pred_nb = nb_model.predict(X_test)\nprint(\"Naive Bayes Classification Report\")\nprint(classification_report(y_test, y_pred_nb))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T19:28:25.040216Z","iopub.execute_input":"2025-02-08T19:28:25.040547Z","iopub.status.idle":"2025-02-08T19:28:25.065230Z","shell.execute_reply.started":"2025-02-08T19:28:25.040521Z","shell.execute_reply":"2025-02-08T19:28:25.064262Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\n\n# Confusion matrix for Random Forest\ncm_rf = confusion_matrix(y_test, y_pred_rf)\nsns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues')\nplt.title(\"Random Forest Confusion Matrix\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T19:45:19.998041Z","iopub.execute_input":"2025-02-08T19:45:19.998370Z","iopub.status.idle":"2025-02-08T19:45:20.169428Z","shell.execute_reply.started":"2025-02-08T19:45:19.998345Z","shell.execute_reply":"2025-02-08T19:45:20.168598Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"combined_dataset.to_csv(\"expanded_dataset_with_results.csv\", index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T19:35:34.137765Z","iopub.execute_input":"2025-02-08T19:35:34.138040Z","iopub.status.idle":"2025-02-08T19:35:34.278199Z","shell.execute_reply.started":"2025-02-08T19:35:34.138020Z","shell.execute_reply":"2025-02-08T19:35:34.277545Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Example metrics (replace with actual results from your evaluation)\nmetrics = {\n    \"Model\": [\"Logistic Regression\", \"Naive Bayes\", \"Random Forest\", \"BERT\"],\n    \"Accuracy\": [accuracy_lr, accuracy_nb, accuracy_rf, accuracy_bert],\n    \"Precision\": [precision_lr, precision_nb, precision_rf, precision_bert],\n    \"Recall\": [recall_lr, recall_nb, recall_rf, recall_bert],\n    \"F1-Score\": [f1_lr, f1_nb, f1_rf, f1_bert],\n}\n\n# Convert to DataFrame and display\nmetrics_df = pd.DataFrame(metrics)\nprint(metrics_df)\n\n# Optionally save the table to a CSV file\nmetrics_df.to_csv(\"model_performance_metrics.csv\", index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T19:36:18.677000Z","iopub.execute_input":"2025-02-08T19:36:18.677336Z","iopub.status.idle":"2025-02-08T19:36:18.687120Z","shell.execute_reply.started":"2025-02-08T19:36:18.677297Z","shell.execute_reply":"2025-02-08T19:36:18.686245Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"batch_size = 5  # Use a smaller batch size\nbert_model.eval()\nbert_predictions = []\n\nwith torch.no_grad():\n    for i in range(0, len(X_test_dense), batch_size):\n        batch_texts = X_test_dense[i:i+batch_size].tolist()\n        inputs, _ = tokenize_data(batch_texts, y_test[i:i+batch_size].tolist())\n        outputs = bert_model(**inputs)\n        batch_predictions = torch.argmax(outputs.logits, axis=1).cpu().numpy()\n        bert_predictions.extend(batch_predictions)\nbert_predictions = np.array(bert_predictions)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T19:52:00.045424Z","iopub.status.idle":"2025-02-08T19:52:00.045799Z","shell.execute_reply":"2025-02-08T19:52:00.045631Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"comparison_df = pd.DataFrame({\n    \"True Label\": y_test.tolist(),\n    \"Logistic Regression\": lr_predictions.tolist(),\n    \"Naive Bayes\": nb_predictions.tolist(),\n    \"Random Forest\": rf_predictions.tolist(),\n    \"BERT\": bert_predictions.tolist(),\n})\n\n# Display a few rows of comparison\nprint(comparison_df.head())\n\n# Optionally save for further analysis\ncomparison_df.to_csv(\"predictions_comparison.csv\", index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T19:52:09.101277Z","iopub.execute_input":"2025-02-08T19:52:09.101639Z","iopub.status.idle":"2025-02-08T19:52:09.115638Z","shell.execute_reply.started":"2025-02-08T19:52:09.101613Z","shell.execute_reply":"2025-02-08T19:52:09.114733Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nmetrics_df.set_index(\"Model\").plot(kind=\"bar\", figsize=(10, 6))\nplt.title(\"Model Performance Comparison\")\nplt.ylabel(\"Score\")\nplt.xticks(rotation=45)\nplt.legend(loc=\"lower right\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T19:53:06.844191Z","iopub.execute_input":"2025-02-08T19:53:06.844540Z","iopub.status.idle":"2025-02-08T19:53:07.088833Z","shell.execute_reply.started":"2025-02-08T19:53:06.844508Z","shell.execute_reply":"2025-02-08T19:53:07.087965Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"agreement = (comparison_df.iloc[:, 1:] == comparison_df[\"True Label\"].values[:, None]).all(axis=1).mean()\nprint(f\"Percentage of agreement among models: {agreement * 100:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T19:53:16.095273Z","iopub.execute_input":"2025-02-08T19:53:16.095621Z","iopub.status.idle":"2025-02-08T19:53:16.102521Z","shell.execute_reply.started":"2025-02-08T19:53:16.095595Z","shell.execute_reply":"2025-02-08T19:53:16.101657Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"disagreements = comparison_df.loc[\n    ~(comparison_df.iloc[:, 1:] == comparison_df[\"True Label\"].values[:, None]).all(axis=1)\n]\nprint(disagreements)\n\n# Optionally save disagreements for analysis\ndisagreements.to_csv(\"model_disagreements.csv\", index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T19:53:21.315948Z","iopub.execute_input":"2025-02-08T19:53:21.316247Z","iopub.status.idle":"2025-02-08T19:53:21.326348Z","shell.execute_reply.started":"2025-02-08T19:53:21.316224Z","shell.execute_reply":"2025-02-08T19:53:21.325490Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nimport numpy as np\n\n# Compute agreement matrix\nagreement_matrix = np.zeros((4, 4))  # Adjust for the number of models\nmodels = [\"Logistic Regression\", \"Naive Bayes\", \"Random Forest\", \"BERT\"]\n\nfor i, model1 in enumerate(models):\n    for j, model2 in enumerate(models):\n        if i <= j:\n            agreement_matrix[i, j] = (\n                (comparison_df[model1] == comparison_df[model2]).mean() * 100\n            )\n        else:\n            agreement_matrix[i, j] = agreement_matrix[j, i]\n\n# Convert to DataFrame for visualization\nagreement_df = pd.DataFrame(agreement_matrix, index=models, columns=models)\n\n# Plot heatmap\nplt.figure(figsize=(8, 6))\nsns.heatmap(agreement_df, annot=True, fmt=\".1f\", cmap=\"Blues\", cbar=True)\nplt.title(\"Model Agreement Heatmap (%)\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T19:54:09.995687Z","iopub.execute_input":"2025-02-08T19:54:09.996007Z","iopub.status.idle":"2025-02-08T19:54:10.205258Z","shell.execute_reply.started":"2025-02-08T19:54:09.995981Z","shell.execute_reply":"2025-02-08T19:54:10.204527Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"comparison_df[\"True Label\"] = comparison_df[\"True Label\"].map({0: \"true\", 1: \"fake\"})\nexpanded_dataset = pd.concat([combined_dataset, comparison_df], axis=1)\nexpanded_dataset.to_csv(\"final_dataset_with_predictions.csv\", index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T19:54:18.359873Z","iopub.execute_input":"2025-02-08T19:54:18.360158Z","iopub.status.idle":"2025-02-08T19:54:18.521962Z","shell.execute_reply.started":"2025-02-08T19:54:18.360135Z","shell.execute_reply":"2025-02-08T19:54:18.521059Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}